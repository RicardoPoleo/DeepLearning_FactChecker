{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyP1fyh0SNKm4XjnRZ/B/Izb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RicardoPoleo/DeepLearning_FactChecker/blob/main/notebooks/Agents/WebService_Agent_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGuQMYFV1vsA"
      },
      "outputs": [],
      "source": [
        "#@title Install Dependencies\n",
        "!pip install sentence-transformers torch transformers datasets fastapi uvicorn\n",
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define the model\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.util import cos_sim\n",
        "import logging\n",
        "\n",
        "# Setup basic configuration for logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "class InformationRetrievalAgent:\n",
        "    def __init__(self, model_path, evidence_file, top_n=5):\n",
        "        self.top_n = top_n  # Parameterize the number of top evidence pieces to retrieve\n",
        "\n",
        "        try:\n",
        "            # Load the model with an option to trust remote code which is necessary for some advanced models\n",
        "            self.model = SentenceTransformer(model_path, trust_remote_code=True)\n",
        "            logging.info(f\"Model loaded successfully from {model_path}.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load the model from {model_path}: {e}\")\n",
        "            raise\n",
        "\n",
        "        try:\n",
        "            # Load the evidence from CSV file\n",
        "            self.evidence_df = pd.read_csv(evidence_file)\n",
        "            self.evidence_texts = self.evidence_df['evidence'].tolist()\n",
        "            logging.info(\"Evidence data loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load evidence from {evidence_file}: {e}\")\n",
        "            raise\n",
        "\n",
        "        try:\n",
        "            # Encode the evidence texts\n",
        "            self.evidence_embeddings = self.model.encode(self.evidence_texts, convert_to_tensor=True)\n",
        "            logging.info(\"Evidence texts encoded successfully.\")\n",
        "        except Exception as e:\n",
        "            logging.error(\"Failed to encode evidence texts: {e}\")\n",
        "            raise\n",
        "\n",
        "    def retrieve_evidence(self, keywords):\n",
        "        try:\n",
        "            # Encode the keywords\n",
        "            keywords_embedding = self.model.encode(keywords, convert_to_tensor=True)\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to encode keywords: {e}\")\n",
        "            return []\n",
        "\n",
        "        # Compute cosine similarities\n",
        "        similarities = cos_sim(keywords_embedding, self.evidence_embeddings)\n",
        "\n",
        "        # Get the top N most similar evidence\n",
        "        top_n_indices = similarities[0].argsort(descending=True)[:self.top_n]\n",
        "\n",
        "        # Retrieve the top N evidence texts\n",
        "        top_evidence = [self.evidence_texts[idx] for idx in top_n_indices]\n",
        "\n",
        "        return top_evidence\n",
        "\n",
        "\n",
        "# Adding in this same cell just to make it easier, however, we should do it in another cell\n",
        "# Using a public URL for easy access\n",
        "evidence_pathfile = \"https://github.com/RicardoPoleo/DeepLearning_FactChecker/raw/main/datasets/healthver_only_evidence.csv\"\n",
        "ir_agent = InformationRetrievalAgent(\n",
        "    model_path='fine-tuned/NFCorpus-256-24-gpt-4o-2024-05-13-203779',\n",
        "    evidence_file=evidence_pathfile,\n",
        "    top_n=5\n",
        ")"
      ],
      "metadata": {
        "id": "eKYGzHQg17bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start the Web Service\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "import subprocess\n",
        "import threading\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class RequestModel(BaseModel):\n",
        "    text: str\n",
        "\n",
        "@app.post(\"/retrieve_evidence\")\n",
        "def retrieve_evidence(request: RequestModel):\n",
        "    keywords = request.text.split()\n",
        "    evidence = ir_agent.retrieve_evidence(keywords)\n",
        "    return {\"evidence\": evidence}\n",
        "\n",
        "def start_uvicorn():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "# Free the port before starting the server\n",
        "!fuser -k 8000/tcp\n",
        "\n",
        "thread = threading.Thread(target=start_uvicorn)\n",
        "thread.start()\n",
        "\n",
        "process = subprocess.Popen([\"lt\", \"--port\", \"8000\"], stdout=subprocess.PIPE)\n",
        "for line in process.stdout:\n",
        "    print(line.decode().strip())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PBa_780V2ABU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}